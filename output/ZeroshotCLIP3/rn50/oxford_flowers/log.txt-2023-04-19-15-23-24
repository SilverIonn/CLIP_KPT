***************
** Arguments **
***************
backbone: 
calibration: True
config_file: configs/trainers/CoOp/rn50.yaml
cutrate: 0.5
dataset: oxford_flowers
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: None
model_dir: 
no_train: False
opts: []
output_dir: output/ZeroshotCLIP3/rn50/oxford_flowers
relevance_refine: False
resume: 
root: /ix/yufeihuang/jia/nlp/prompt/data
seed: -1
source_domains: None
target_domains: None
trainer: ZeroshotCLIP3
transforms: None
vb_dir: /ihome/yufeihuang/jiy130/Prompt/CoOp/knowledgebase
vbsize: 100
verbalizer: True
************
** Config **
************
CALIBRATION: True
CALIBRATION_CUT: 0.5
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: -1
  ROOT: /ix/yufeihuang/jia/nlp/prompt/data
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: RN50
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/ZeroshotCLIP3/rn50/oxford_flowers
RELEVANCE_REFINE: False
RESUME: 
SEED: -1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: ZeroshotCLIP3
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBALIZER:
  DIR: /ihome/yufeihuang/jiy130/Prompt/CoOp/knowledgebase/oxford_flowers
  SIZE: 100
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Red Hat Enterprise Linux (x86_64)
GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.17

Python version: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: 
GPU 0: NVIDIA A100-PCIE-40GB
GPU 1: NVIDIA A100-PCIE-40GB
GPU 2: NVIDIA A100-PCIE-40GB
GPU 3: NVIDIA A100-PCIE-40GB

Nvidia driver version: 515.65.01
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] numpy==1.23.5
[pip3] torch==1.13.1
[pip3] torchaudio==0.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               11.3.1               h2bc3f7f_2  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py38h7f8727e_0  
[conda] mkl_fft                   1.3.1            py38hd3c417c_0  
[conda] mkl_random                1.2.2            py38h51133e4_0  
[conda] numpy                     1.23.5           py38h14f4228_0  
[conda] numpy-base                1.23.5           py38h31eccc5_0  
[conda] pytorch                   1.13.1          py3.8_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_3    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchaudio                0.13.1               py38_cu117    pytorch
[conda] torchvision               0.14.1               py38_cu117    pytorch
        Pillow (9.4.0)

Loading trainer: ZeroshotCLIP3
Loading dataset: OxfordFlowers
Reading split from /ix/yufeihuang/jia/nlp/prompt/data/oxford_flowers/split_zhou_OxfordFlowers.json
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  4,093
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: RN50)
Selected examples (mixed) [2440, 2987, 1578, 1672, 899, 2404, 674, 1387, 2193, 293, 2378, 2113, 3190, 703, 1972, 3453, 845, 843, 1530, 2180, 3043, 2782, 623, 2227, 1577, 3165, 3733, 1881, 18, 2785, 3802, 496, 2976, 2500, 1963, 3673, 967, 1765, 1538, 49, 925, 3948, 562, 3535, 692, 2494, 1912, 2961, 1822, 1112, 4000, 315, 3162, 915, 133, 584, 583, 2937, 534, 3425, 1604, 371, 2633, 906, 2514, 944, 1062, 188, 2216, 3124, 3934, 829, 2304, 3157, 3721, 1152, 87, 1473, 1824, 3028, 1627, 1842, 1968, 79, 822, 257, 742, 3048, 910, 3186, 224, 448, 2766, 1999, 3313, 3650, 3007, 27, 50, 3642, 2625, 3328, 3388, 945, 3475, 35, 281, 2507, 1537, 1504, 3713, 2996, 1462, 931, 1308, 2532, 777, 1044, 2765, 1367, 124, 2617, 1050, 3946, 2670, 3853, 85, 2671, 435, 1214, 1018, 2200, 2778, 1705, 2363, 959, 1272, 1539, 992, 1038, 1212, 3777, 2672, 3272, 3626, 1628, 2975, 203, 2510, 53, 1015, 2727, 1119, 3605, 1731, 204, 3554, 593, 4004, 3231, 749, 828, 3947, 3898, 4014, 730, 2849, 3132, 2806, 1509, 3092, 1556, 1412, 2271, 111, 2460, 701, 2097, 2313, 2477, 535, 4080, 3831, 3783, 1312, 2926, 231, 3305, 210, 3971, 2592, 1658, 1818, 2099, 856, 2639, 2522, 2127, 1455, 832]
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Load support dataloader successfully! size: 200
num of org label words: 3152
cali text features shape: torch.Size([3152, 1024])
the calibration logits is tensor([[18.2656, 23.0781, 24.7812,  ..., 25.4219, 23.2812, 23.0938],
        [21.0312, 25.3750, 25.2656,  ..., 24.4062, 24.8906, 24.0156],
        [16.5156, 21.0938, 24.4844,  ..., 25.8281, 24.0469, 21.6719],
        ...,
        [22.9531, 25.3281, 26.0781,  ..., 28.0625, 24.5156, 23.7344],
        [20.8281, 18.5625, 23.9688,  ..., 24.0312, 24.5156, 22.1875],
        [20.7031, 17.5312, 18.5156,  ..., 18.2344, 22.0625, 19.4062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<MmBackward0>)
cc_logits shape: torch.Size([200, 3152])
Phase 1 [18, 3, 8, 11, 38, 7, 31, 94, 23, 92, 5, 1, 96, 48, 54, 12, 17, 78, 46, 18, 1, 6, 74, 30, 44, 37, 1, 1, 53, 39, 38, 5, 1, 11, 12, 1, 1, 1, 8, 68, 1, 45, 54, 8, 5, 9, 1, 10, 43, 41, 11, 58, 54, 12, 18, 49, 8, 5, 1, 1, 9, 20, 96, 99, 37, 7, 6, 66, 9, 32, 5, 4, 52, 94, 70, 56, 62, 11, 2, 16, 60, 66, 14, 6, 1, 75, 38, 27, 45, 6, 55, 84, 18, 87, 12, 33, 73, 8, 23, 8, 85, 9]

register_calibrate_logits starting shape: torch.Size([3152])
logits shape -1 :3152
rm_calibrate_ids: {0, 1, 6, 8, 9, 10, 12, 17, 18, 21, 29, 30, 31, 32, 35, 37, 38, 40, 41, 43, 45, 46, 48, 49, 50, 52, 53, 58, 59, 63, 64, 65, 77, 78, 80, 81, 82, 83, 84, 85, 86, 101, 102, 111, 113, 114, 116, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 152, 154, 156, 158, 160, 162, 163, 164, 166, 167, 170, 171, 172, 173, 175, 177, 178, 180, 183, 184, 185, 186, 187, 188, 190, 192, 193, 194, 195, 197, 198, 199, 200, 201, 205, 208, 210, 213, 214, 215, 216, 217, 220, 224, 230, 231, 232, 233, 234, 247, 252, 259, 266, 268, 269, 270, 271, 272, 275, 276, 278, 280, 284, 286, 292, 295, 298, 300, 302, 306, 320, 321, 325, 326, 327, 328, 330, 331, 333, 334, 336, 344, 345, 347, 352, 353, 384, 389, 427, 428, 429, 430, 431, 433, 434, 435, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 451, 452, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 470, 471, 472, 473, 474, 475, 477, 478, 479, 482, 483, 484, 485, 486, 487, 491, 492, 495, 496, 499, 500, 501, 504, 505, 510, 511, 512, 515, 516, 517, 520, 521, 523, 524, 526, 528, 530, 531, 532, 533, 534, 535, 536, 538, 539, 541, 549, 550, 552, 553, 554, 555, 558, 560, 561, 562, 569, 575, 590, 607, 615, 628, 636, 637, 638, 639, 640, 642, 643, 648, 649, 650, 651, 653, 654, 655, 656, 657, 658, 659, 660, 662, 663, 665, 666, 667, 668, 669, 671, 672, 674, 675, 676, 680, 682, 693, 694, 697, 698, 699, 700, 701, 702, 704, 705, 707, 708, 709, 710, 711, 712, 713, 714, 715, 717, 718, 719, 720, 724, 725, 727, 728, 729, 731, 733, 736, 737, 738, 739, 740, 741, 743, 744, 745, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 768, 769, 770, 771, 775, 777, 778, 779, 780, 781, 782, 784, 785, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 800, 801, 803, 805, 806, 808, 810, 811, 814, 815, 817, 821, 822, 823, 824, 826, 827, 828, 829, 830, 831, 832, 833, 834, 836, 840, 841, 842, 843, 844, 846, 847, 848, 849, 850, 851, 852, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 866, 868, 869, 870, 871, 872, 874, 875, 876, 877, 879, 880, 881, 884, 887, 888, 890, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 906, 910, 911, 919, 920, 922, 923, 925, 926, 927, 928, 929, 930, 932, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 952, 955, 959, 960, 961, 962, 963, 968, 969, 970, 971, 972, 973, 974, 975, 976, 981, 982, 983, 986, 988, 989, 990, 997, 1000, 1003, 1004, 1005, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1016, 1017, 1018, 1019, 1021, 1023, 1024, 1026, 1027, 1028, 1029, 1030, 1032, 1035, 1036, 1038, 1039, 1041, 1050, 1053, 1055, 1056, 1064, 1065, 1068, 1072, 1073, 1074, 1075, 1077, 1082, 1083, 1092, 1093, 1098, 1099, 1105, 1118, 1132, 1133, 1134, 1135, 1137, 1138, 1140, 1141, 1144, 1145, 1146, 1147, 1150, 1151, 1152, 1153, 1155, 1156, 1158, 1159, 1160, 1161, 1162, 1165, 1166, 1169, 1171, 1176, 1177, 1178, 1179, 1180, 1181, 1184, 1187, 1189, 1190, 1192, 1193, 1194, 1195, 1197, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1210, 1211, 1212, 1214, 1215, 1216, 1218, 1220, 1222, 1226, 1228, 1229, 1232, 1233, 1235, 1237, 1239, 1241, 1243, 1245, 1246, 1248, 1250, 1252, 1254, 1255, 1256, 1260, 1261, 1262, 1264, 1265, 1266, 1267, 1268, 1269, 1271, 1272, 1273, 1274, 1275, 1276, 1278, 1284, 1285, 1288, 1290, 1291, 1292, 1293, 1294, 1296, 1300, 1301, 1302, 1304, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1328, 1330, 1331, 1336, 1337, 1340, 1344, 1346, 1349, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1362, 1365, 1368, 1371, 1372, 1377, 1380, 1381, 1382, 1383, 1384, 1386, 1388, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1401, 1402, 1404, 1405, 1406, 1407, 1408, 1411, 1413, 1414, 1415, 1416, 1418, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1431, 1433, 1434, 1440, 1442, 1444, 1446, 1447, 1450, 1453, 1457, 1466, 1467, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1486, 1487, 1488, 1489, 1490, 1494, 1495, 1496, 1498, 1500, 1501, 1504, 1510, 1512, 1513, 1524, 1531, 1536, 1541, 1542, 1544, 1551, 1553, 1555, 1556, 1558, 1559, 1560, 1561, 1563, 1564, 1565, 1566, 1570, 1572, 1575, 1580, 1581, 1582, 1589, 1595, 1598, 1600, 1601, 1602, 1617, 1618, 1620, 1625, 1626, 1628, 1630, 1631, 1633, 1635, 1636, 1638, 1640, 1645, 1647, 1649, 1650, 1652, 1655, 1656, 1658, 1663, 1665, 1666, 1672, 1676, 1680, 1682, 1685, 1687, 1689, 1691, 1692, 1694, 1695, 1696, 1699, 1706, 1717, 1727, 1780, 1786, 1787, 1788, 1789, 1790, 1792, 1797, 1802, 1812, 1816, 1819, 1827, 1828, 1831, 1832, 1833, 1834, 1835, 1837, 1838, 1839, 1840, 1842, 1843, 1845, 1849, 1851, 1852, 1853, 1854, 1855, 1857, 1858, 1859, 1860, 1861, 1864, 1865, 1872, 1878, 1880, 1884, 1887, 1890, 1891, 1892, 1893, 1895, 1896, 1898, 1899, 1900, 1901, 1902, 1903, 1906, 1907, 1908, 1913, 1915, 1917, 1921, 1922, 1923, 1925, 1926, 1929, 1932, 1934, 1935, 1936, 1937, 1938, 1940, 1943, 1944, 1946, 1947, 1948, 1949, 1950, 1952, 1953, 1955, 1956, 1959, 1960, 1962, 1964, 1965, 1966, 1967, 1970, 1971, 1974, 1975, 1979, 1980, 1982, 1986, 1990, 1992, 1994, 1995, 1996, 1997, 2002, 2007, 2008, 2039, 2042, 2043, 2045, 2056, 2059, 2068, 2080, 2082, 2088, 2089, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2109, 2111, 2114, 2115, 2118, 2119, 2121, 2122, 2125, 2128, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2140, 2142, 2143, 2144, 2145, 2146, 2147, 2149, 2150, 2154, 2157, 2158, 2161, 2162, 2164, 2166, 2168, 2169, 2172, 2173, 2178, 2179, 2180, 2183, 2185, 2186, 2187, 2189, 2190, 2191, 2197, 2200, 2202, 2203, 2206, 2207, 2208, 2209, 2217, 2221, 2223, 2224, 2228, 2229, 2230, 2233, 2236, 2238, 2240, 2242, 2247, 2253, 2256, 2257, 2258, 2260, 2261, 2262, 2264, 2265, 2266, 2269, 2273, 2274, 2275, 2277, 2279, 2280, 2281, 2282, 2283, 2285, 2287, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2301, 2303, 2306, 2307, 2308, 2311, 2315, 2317, 2319, 2320, 2321, 2322, 2323, 2326, 2327, 2331, 2335, 2336, 2337, 2339, 2340, 2341, 2346, 2348, 2350, 2355, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2367, 2368, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2394, 2395, 2397, 2399, 2404, 2405, 2406, 2407, 2408, 2409, 2411, 2414, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2432, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2445, 2446, 2447, 2451, 2452, 2453, 2455, 2456, 2457, 2459, 2460, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2477, 2478, 2479, 2480, 2484, 2485, 2486, 2487, 2492, 2493, 2494, 2496, 2497, 2499, 2503, 2505, 2506, 2509, 2512, 2514, 2516, 2517, 2518, 2520, 2521, 2522, 2524, 2526, 2527, 2528, 2529, 2530, 2532, 2533, 2536, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2550, 2551, 2552, 2556, 2557, 2558, 2559, 2560, 2562, 2564, 2565, 2566, 2568, 2570, 2573, 2574, 2575, 2576, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2631, 2634, 2637, 2638, 2640, 2641, 2642, 2643, 2644, 2645, 2647, 2648, 2649, 2650, 2651, 2652, 2655, 2656, 2657, 2658, 2659, 2661, 2663, 2673, 2674, 2677, 2679, 2681, 2683, 2684, 2689, 2690, 2692, 2694, 2695, 2696, 2697, 2698, 2699, 2701, 2703, 2705, 2707, 2708, 2709, 2712, 2713, 2714, 2715, 2716, 2717, 2718, 2721, 2722, 2723, 2726, 2727, 2730, 2734, 2735, 2736, 2743, 2744, 2747, 2750, 2753, 2754, 2755, 2757, 2764, 2767, 2769, 2770, 2772, 2773, 2779, 2780, 2781, 2783, 2785, 2786, 2787, 2789, 2790, 2792, 2793, 2796, 2797, 2798, 2801, 2802, 2803, 2804, 2805, 2807, 2808, 2813, 2814, 2815, 2816, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2828, 2830, 2831, 2833, 2834, 2836, 2838, 2839, 2848, 2851, 2854, 2855, 2858, 2863, 2868, 2872, 2873, 2876, 2877, 2879, 2882, 2893, 2895, 2899, 2901, 2902, 2903, 2905, 2906, 2907, 2908, 2909, 2913, 2914, 2915, 2916, 2917, 2920, 2921, 2923, 2924, 2925, 2926, 2927, 2931, 2933, 2934, 2935, 2940, 2941, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2955, 2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2967, 2970, 2971, 2973, 2975, 2977, 2979, 2984, 2988, 2990, 2991, 2992, 2993, 2995, 2996, 2997, 2998, 2999, 3000, 3002, 3003, 3005, 3006, 3007, 3008, 3009, 3010, 3012, 3013, 3014, 3015, 3016, 3018, 3019, 3020, 3023, 3024, 3026, 3027, 3028, 3031, 3032, 3034, 3038, 3039, 3042, 3045, 3047, 3050, 3051, 3052, 3053, 3056, 3058, 3059, 3060, 3061, 3063, 3064, 3065, 3066, 3069, 3070, 3071, 3072, 3074, 3077, 3085, 3086, 3089, 3091, 3092, 3096, 3097, 3098, 3106, 3107, 3108, 3109, 3111, 3112, 3114, 3120, 3122, 3123, 3128, 3132, 3133, 3136, 3137, 3143, 3144, 3148, 3149, 3151}, shape 1576
