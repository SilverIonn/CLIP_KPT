***************
** Arguments **
***************
backbone: 
calibration: True
config_file: configs/trainers/CoOp/vit_b16.yaml
cutrate: 0.15
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: None
model_dir: 
no_train: False
opts: []
output_dir: output/ZeroshotCLIP3/vit_b16/eurosat
relevance_refine: False
resume: 
root: /ix/yufeihuang/jia/nlp/prompt/data
seed: -1
source_domains: None
target_domains: None
trainer: ZeroshotCLIP3
transforms: None
vb_dir: /ihome/yufeihuang/jiy130/Prompt/CoOp/knowledgebase
vbsize: 20
verbalizer: True
************
** Config **
************
CALIBRATION: True
CALIBRATION_CUT: 0.15
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: -1
  ROOT: /ix/yufeihuang/jia/nlp/prompt/data
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/ZeroshotCLIP3/vit_b16/eurosat
RELEVANCE_REFINE: False
RESUME: 
SEED: -1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: ZeroshotCLIP3
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBALIZER:
  DIR: /ihome/yufeihuang/jiy130/Prompt/CoOp/knowledgebase/EuroSAT
  SIZE: 20
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Red Hat Enterprise Linux (x86_64)
GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.17

Python version: 3.8.16 (default, Jan 17 2023, 23:13:24)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: 
GPU 0: NVIDIA A100-PCIE-40GB
GPU 1: NVIDIA A100-PCIE-40GB
GPU 2: NVIDIA A100-PCIE-40GB
GPU 3: NVIDIA A100-PCIE-40GB

Nvidia driver version: 515.65.01
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] numpy==1.23.5
[pip3] torch==1.13.1
[pip3] torchaudio==0.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               11.3.1               h2bc3f7f_2  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py38h7f8727e_0  
[conda] mkl_fft                   1.3.1            py38hd3c417c_0  
[conda] mkl_random                1.2.2            py38h51133e4_0  
[conda] numpy                     1.23.5           py38h14f4228_0  
[conda] numpy-base                1.23.5           py38h31eccc5_0  
[conda] pytorch                   1.13.1          py3.8_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_3    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchaudio                0.13.1               py38_cu117    pytorch
[conda] torchvision               0.14.1               py38_cu117    pytorch
        Pillow (9.4.0)

Loading trainer: ZeroshotCLIP3
Loading dataset: EuroSAT
Reading split from /ix/yufeihuang/jia/nlp/prompt/data/eurosat/split_zhou_EuroSAT.json
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  13,500
# val      5,400
# test     8,100
---------  -------
['Annual Crop Land', 'Forest', 'Herbaceous Vegetation Land', 'Highway or Road', 'Industrial Buildings', 'Pasture Land', 'Permanent Crop Land', 'Residential Buildings', 'River', 'Sea or Lake']
Loading CLIP (backbone: ViT-B/16)
Selected examples (mixed) [5140, 3898, 3706, 565, 10324, 12921, 5257, 4139, 1491, 10063, 9654, 1900, 8409, 10223, 3991, 3394, 4381, 4655, 1686, 2454, 5897, 4632, 5720, 9331, 6511, 625, 3992, 1085, 13456, 1488, 477, 12594, 6401, 5550, 4059, 4063, 12859, 6568, 6130, 7497, 1912, 11861, 5824, 9374, 7362, 10825, 12250, 1563, 1374, 2054, 721, 685, 11114, 13036, 1748, 50, 836, 12576, 2334, 1693, 6009, 13083, 2585, 6170, 11858, 11419, 10697, 8593, 12103, 1031, 4420, 5267, 9075, 5771, 1324, 11095, 5923, 2314, 11811, 8177, 6793, 7066, 13141, 10330, 12017, 9156, 2728, 3963, 12558, 3450, 6270, 8365, 2941, 5221, 1936, 12142, 8087, 13256, 6252, 6644, 2496, 8119, 8388, 7721, 1105, 5307, 6154, 6602, 12770, 11671, 2428, 2816, 9110, 2057, 5048, 11524, 11991, 742, 2377, 8539, 4789, 6889, 3582, 5200, 8895, 2683, 20, 7991, 12401, 2547, 11659, 2022, 558, 5484, 6095, 4261, 11086, 1009, 12640, 7774, 4805, 6321, 3131, 10793, 407, 1442, 3491, 11116, 10436, 9479, 5995, 12378, 4688, 2536, 4682, 4457, 3353, 10513, 968, 2767, 13491, 8991, 5906, 8227, 6226, 3827, 2693, 1382, 9762, 6167, 6728, 10705, 3913, 12415, 11644, 10701, 8340, 6114, 5440, 2960, 1499, 11663, 2243, 9804, 1553, 3905, 12572, 3736, 9985, 6439, 3880, 11939, 9344, 7029, 1298, 12480, 2620, 1858, 309, 5205]
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Load support dataloader successfully! size: 200
num of org label words: 74
cali text features shape: torch.Size([74, 512])
the calibration logits is tensor([[29.9844, 30.7812, 31.5000,  ..., 27.4219, 31.8594, 25.4688],
        [32.3438, 31.8438, 31.8125,  ..., 30.0312, 33.5625, 27.7188],
        [30.1406, 29.3594, 28.2656,  ..., 27.5938, 28.5781, 27.4688],
        ...,
        [27.8438, 27.0312, 27.1719,  ..., 25.7344, 26.6094, 26.9062],
        [28.0938, 26.4375, 27.6406,  ..., 25.5625, 27.0938, 26.8281],
        [28.8750, 28.9688, 29.4688,  ..., 24.6875, 29.4844, 24.4844]],
       device='cuda:0', dtype=torch.float16, grad_fn=<MmBackward0>)
cc_logits shape: torch.Size([200, 74])
Phase 1 [1, 21, 1, 1, 5, 1, 1, 21, 21, 1]

register_calibrate_logits starting shape: torch.Size([74])
logits shape -1 :74
rm_calibrate_ids: {64, 67, 71, 73, 52, 53, 56, 58, 59, 61, 63}, shape 11
Phase 2 [1, 21, 1, 1, 5, 1, 1, 21, 12, 1]

num of label words after cc: 65
cali_logits shape: torch.Size([65])
Prompts: ['a centered satellite photo of annual crop land.', 'a centered satellite photo of forest.', 'a centered satellite photo of forward.', 'a centered satellite photo of front.', 'a centered satellite photo of bow.', 'a centered satellite photo of foremost.', 'a centered satellite photo of stem.', 'a centered satellite photo of prow.', 'a centered satellite photo of anterior.', 'a centered satellite photo of aft.', 'a centered satellite photo of nose.', 'a centered satellite photo of lateral.', 'a centered satellite photo of forefront.', 'a centered satellite photo of seafaring.', 'a centered satellite photo of sailing.', 'a centered satellite photo of navigation.', 'a centered satellite photo of watercraft.', 'a centered satellite photo of vessel.', 'a centered satellite photo of frontline.', 'a centered satellite photo of frontal.', 'a centered satellite photo of frontward.', 'a centered satellite photo of forepart.', 'a centered satellite photo of herbaceous vegetation land.', 'a centered satellite photo of highway or road.', 'a centered satellite photo of industrial buildings.', 'a centered satellite photo of industrial sector.', 'a centered satellite photo of industrial revolution.', 'a centered satellite photo of british industrial architecture.', 'a centered satellite photo of modern architecture.', 'a centered satellite photo of pasture land.', 'a centered satellite photo of permanent crop land.', 'a centered satellite photo of residential buildings.', 'a centered satellite photo of zoning.', 'a centered satellite photo of subdivision.', 'a centered satellite photo of houses.', 'a centered satellite photo of rural.', 'a centered satellite photo of deed.', 'a centered satellite photo of industrial district.', 'a centered satellite photo of commercial area.', 'a centered satellite photo of single-family housing.', 'a centered satellite photo of multi-family residential.', 'a centered satellite photo of mobile home.', 'a centered satellite photo of house.', 'a centered satellite photo of urban density.', 'a centered satellite photo of bespoke.', 'a centered satellite photo of floor area ratio.', 'a centered satellite photo of mansion.', 'a centered satellite photo of land development.', 'a centered satellite photo of tenement.', 'a centered satellite photo of transport infrastructure.', 'a centered satellite photo of restrictive covenant.', 'a centered satellite photo of speculation.', 'a centered satellite photo of river.', 'a centered satellite photo of lake.', 'a centered satellite photo of stream.', 'a centered satellite photo of billabong.', 'a centered satellite photo of floodplain.', 'a centered satellite photo of channel.', 'a centered satellite photo of confluence.', 'a centered satellite photo of watercourse.', 'a centered satellite photo of brazos.', 'a centered satellite photo of klamath.', 'a centered satellite photo of dnieper.', 'a centered satellite photo of creek.', 'a centered satellite photo of sea or lake.']
text feature size: torch.Size([65, 512])
Loading evaluator: Classification
Note that load_model() is skipped as no pretrained model is given (ignore this if it's done on purpose)
Evaluate on the *test* set
=> result
* total: 8,100
* correct: 4,110
* accuracy: 50.7%
* error: 49.3%
* macro_f1: 46.5%
